%&<latex>
\documentclass[letterpaper,12pt]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% preamble %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{../utils/preamble.tex}
\input{../utils/macros.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\doublespacing
\raggedright
\setlength{\parindent}{0.5in}
\begin{linenumbers}

\begin{titlepage}
    \begin{flushleft}
        \sffamily

        \MakeUppercase{\large\bfseries Title}

        \vspace{12pt}
        \textbf{Running head:} \MakeUppercase{Running head}

        \vspace{12pt}
        Jamie R.\ Oaks$^{1,2}$ and Mark T.\ Holder$^{1}$

        \bigskip
        $^1$\emph{Department of Ecology and Evolutionary Biology,
            % Biodiversity Institute,
            University of Kansas,
            Lawrence, Kansas 66045}\\[.1in]
        $^2$\emph{Corresponding author} (\href{mailto:joaks1@gmail.com}{\tt
        joaks1@gmail.com})\\

    \end{flushleft}
\end{titlepage}

{\sffamily
    \noindent\textbf{ABSTRACT} \\
    \noindent Abstract here \ldots

    \vspace{12pt}
    \noindent\textbf{KEY WORDS: } 
}

\newpage
\noindent \ldots

\section*{Methods}

\subsection*{The model}
We follow much of the notation of \citet{Oaks2012}, but modify it to
accommodate the new model \ldots

We assume an investigator is interested in inferring the distribution
of divergence times among \npairs{} pairs of populations.
For each pair $i$, \popSampleSize{i}{} genome copies have been sampled, with
\popSampleSize{1}{i} copies sampled from population 1, and \popSampleSize{2}{i}
sampled from population 2.
From these genomes, let \nloci{i} be the number of DNA sequence loci collected
for population pair $i$, and \nlociTotal be the total number of unique loci
sampled across the \npairs{} pairs of populations.
We use \alignment{i}{j} to represent the multiple sequence alignment of
locus $j$ for population pair $i$.
$\alignmentVector = (\alignment{1}{1}, \ldots,
    \alignment{\npairs{}}{\nloci{\npairs{}}})$
is the full dataset,
i.e., a vector of sequence alignments for all pairs and loci.
We let \geneTree{i}{j} represent the gene tree upon which \alignment{i}{j}
evolved according to fixed \hky substitution model parameters \hkyModel{i}{j}.
The investigtor must specify the parameters of all
$\hkyModelVector = (\hkyModel{1}{1}, \ldots,
\hkyModel{\npairs{}}{\nloci{\npairs{}}})$
substitution models by which the alignments evolved along the
$\geneTreeVector = (\geneTree{1}{1}, \ldots,
\geneTree{\npairs{}}{\nloci{\npairs{}}})$
gene trees.
Furthermore, the investigator must specify a vector of fixed contants
$\ploidyScalarVector = (\ploidyScalar{1}{1}, \ldots,
\ploidyScalar{\npairs{}}{\nloci{\npairs{}}})$
that scale the population size parameters for known differences in ploidy among
loci and/or differences in generation times among population pairs.
Lastly, the investigator must also specify a vector of fixed constants
$\mutationRateScalarConstantVector = (\mutationRateScalarConstant{1}{1},
\ldots, \mutationRateScalarConstant{\npairs{}}{\nloci{\npairs{}}})$
that scale the population size parameters for known differences in
mutation rates among loci and/or among taxa.

\begin{linenomath}
With \alignmentVector, \hkyModelVector, \ploidyScalarVector, and
\mutationRateScalarConstantVector in hand, the joint posterior distribution
of our model is given by
\begin{equation}
    p(\geneTreeVector, \divTimeMapVector, \demographicParamVector, 
    \locusMutationRateScalarVector, \locusRateHetShapeParameter \given
    \alignmentVector, \hkyModelVector, \ploidyScalarVector,
    \mutationRateScalarConstantVector) =
    \frac{p(\alignmentVector \given \geneTreeVector, \hkyModelVector)
        p(\geneTreeVector \given \divTimeMapVector, \demographicParamVector,
        \locusMutationRateScalarVector, \ploidyScalarVector,
        \mutationRateScalarConstantVector)
        p(\locusMutationRateScalarVector \given \locusRateHetShapeParameter)
        p(\locusRateHetShapeParameter)
        p(\divTimeMapVector)
        p(\demographicParamVector)}{
        p(\alignmentVector)},
    \label{eq:fullModelCompact}
\end{equation}
where
$\divTimeMapVector = (\divTimeMap{1}, \ldots, \divTimeMap{\npairs{}})$
is a vector of population divergence times for each of \npairs{} pairs,
$\demographicParamVector = (\demographicParams{1}, \ldots,
\demographicParams{\npairs{}})$
is a vector of the demographic parameters for each of the \npairs{} population
pairs,
$\locusMutationRateScalarVector = (\locusMutationRateScalar{1}, \ldots
\locusMutationRateScalar{\nlociTotal})$
is a vector of locus-specific mutation-rate scaling parameters for each of the
\nlociTotal loci,
\locusRateHetShapeParameter is the shape parameter of a gamma-distributed
prior on \locusMutationRateScalar{}, and
$p(\alignmentVector)$ is the probability of the data (or the marginal
likelihood of the model).
\end{linenomath}

\begin{linenomath}
To avoid calculating the likelihood terms of Equation \ref{eq:fullModelCompact},
we distill each sequence alignment \alignment{}{} into a vector of insufficient
summary statistics \alignmentSS{}{}, thus replacing the full dataset
$\alignmentVector = (\alignment{1}{1}, \ldots,
    \alignment{\npairs{}}{\nloci{\npairs{}}})$
with vectors of summary statistics for each alignment
$\ssVectorObs = (\alignmentSSObs{1}{1}, \ldots,
    \alignmentSSObs{\npairs{}}{\nloci{\npairs{}}})$.
For each populationn pair, the means of the summary statistics are calculated
across the \nloci{} loci, reducing the vector to
$\ssVectorObs = (\alignmentSSObs{1}{}, \ldots,
    \alignmentSSObs{\npairs{}}{})$.
This allows us to estimate the approximate joint posterior distribution
{\small
\begin{equation}
    p(\geneTreeVector, \divTimeMapVector, \demographicParamVector, 
    \locusMutationRateScalarVector, \locusRateHetShapeParameter \given
    \ssSpace, \hkyModelVector, \ploidyScalarVector,
    \mutationRateScalarConstantVector) =
    \frac{p(\ssSpace \given \geneTreeVector, \hkyModelVector)
        p(\geneTreeVector \given \divTimeMapVector, \demographicParamVector,
        \locusMutationRateScalarVector, \ploidyScalarVector,
        \mutationRateScalarConstantVector)
        p(\locusMutationRateScalarVector \given \locusRateHetShapeParameter)
        p(\locusRateHetShapeParameter)
        p(\divTimeMapVector)
        p(\demographicParamVector)}{
        p(\ssSpace)},
    \label{eq:approxModelCompact}
\end{equation}
}
where \ssSpace is the multidimensional Euclidean space around the vector of
summary statistics, the radius of which is the tolerance \tol.
The approximation of this posterior is caused by the insufficiency of the
statistics and the \tol being greater than zero.
We describe the full model in detail before delving into the numerical
method of estimating the approximate model.
\end{linenomath}

\subsubsection*{Likelihood terms of Equation \ref{eq:fullModelCompact}}
\begin{linenomath}
The likelihood terms of Equation \ref{eq:fullModelCompact} can
be expanded out as a product over population pairs and loci
\begin{equation}
    p(\alignmentVector \given \geneTreeVector, \hkyModelVector)
    p(\geneTreeVector \given \divTimeMapVector, \demographicParamVector,
    \locusMutationRateScalarVector, \ploidyScalarVector,
    \mutationRateScalarConstantVector) = 
    \prod_{i=1}^{\npairs{}}
    \prod_{j=1}^{\nloci{i}}
    p(\alignment{i}{j} \given \geneTree{i}{j}, \hkyModel{i}{j})
    p(\geneTree{i}{j} \given \divTimeMap{i}, \demographicParams{i},
    \locusMutationRateScalar{j}, \ploidyScalar{i}{j},
    \mutationRateScalarConstant{i}{j}).
    \label{eq:modelLikelihoodExpanded}
\end{equation}
The first term,
$p(\alignment{i}{j} \given \geneTree{i}{j}, \hkyModel{i}{j})$,
is the probability of the sequence alignment of locus $j$ for population pair
$i$ given the gene tree and \hky substitution model paramters \citep[i.e., the
``Felsenstein likelhood'';][]{Felsenstein1981}.
The model allows for an intra-locus recombination rate \recombinationRate,
which, for simplicity, is assumed to be zero in Equation
\ref{eq:fullModelCompact}.
If \recombinationRate is non-zero, this term requires an additional product
over the columns (sites) of each sequence alignment to allow sites to have
different genealogies.
The second term,
p(\geneTree{i}{j} \given \divTimeMap{i}, \demographicParams{i},
\locusMutationRateScalar{j}, \ploidyScalar{i}{j},
\mutationRateScalarConstant{i}{j}),
is the probability of the gene tree under a multi-population coalescent model
(i.e., species tree) where the ancestral population of pair $i$ diverges
and gives rise to the two sampled descendant populations.
Each \demographicParams contains the following demographic parameters:
The mutation-scaled sizes of the ancestral, \ancestralTheta{}, and descendant
populations, \descendantTheta{1}{} and \descendantTheta{2}{};
the proportion of the first, \bottleScalar{1}{}, and second population,
\bottleScalar{2}{}, that persists during bottlenecks that begin immmediately
after divergence in forward-time;
the proportion of time between present and divergence when the bottlenecks
end for both populations, \bottleTime{};
and the symmetric migration rate between the descendant populations,
\migrationRate{}.
Thus, the probability of the $\popSampleSize{i}{}-1$ coalescence times (node
heights) of gene tree \geneTree{i}{j} is given by a multi-population
Kingman-coalescent model \citep{Kingman1982} where the ancestral population of
size
$\ancestralTheta{i}\ploidyScalar{i}{j}\mutationRateScalarConstant{i}{j}\locusMutationRateScalar{j}$
diverges at time \divTimeMap{i} into two descendant populations of constant
size
$\descendantTheta{1}{i}\ploidyScalar{i}{j}\mutationRateScalarConstant{i}{j}\locusMutationRateScalar{j}\bottleScalar{1}{i}$
and
$\descendantTheta{2}{i}\ploidyScalar{i}{j}\mutationRateScalarConstant{i}{j}\locusMutationRateScalar{j}\bottleScalar{2}{i}$,
which, after time $\divTimeMap{i}\bottleTime{i}$, grow exponentially to their
present size 
$\descendantTheta{1}{i}\ploidyScalar{i}{j}\mutationRateScalarConstant{i}{j}\locusMutationRateScalar{j}$
and
$\descendantTheta{2}{i}\ploidyScalar{i}{j}\mutationRateScalarConstant{i}{j}\locusMutationRateScalar{j}$,
respectively.
Following divergence, the descendant populations of pair $i$ exchange migrants at a symmetric rate of
\migrationRate{i}.
\end{linenomath}


\subsubsection*{Prior terms of Equation \ref{eq:fullModelCompact}}
\begin{linenomath}
The term $p(\locusRateHetShapeParameter)$ is the prior density
function for the shape-parameter for the gamma-distributed prior on
rate heterogeneity among loci.
This prior is $\locusRateHetShapeParameter \sim U(1, 20)$.
The prior probability of the vector of locus-specific mutation-rate scaling parameters
given \locusRateHetShapeParameter then expands out as a product over
the loci
\begin{equation}
    p(\locusMutationRateScalarVector \given \locusRateHetShapeParameter) =
    \prod_{j=1}^{\nlociTotal}
    p(\locusMutationRateScalar{j} \given \locusRateHetShapeParameter),
    \label{eq:locusRateHetPrior}
\end{equation}
where each \locusMutationRateScalar{} is independently and identicially
distributed (\iid) as
$\locusMutationRateScalar{} \sim Gamma(\locusRateHetShapeParameter,
1/\locusRateHetShapeParameter)$.
If the recombination rate \recombinationRate is allowed to be
non-zero, the prior term $p(\recombinationRate)$ would be added
to Equation \ref{eq:fullModelCompact}, and the prior would be
$\recombinationRate \sim Gamma(\gammaShape{\recombinationRate},
\gammaScale{\recombinationRate})$.
\end{linenomath}

\begin{linenomath}
The prior term for the demographic parameters, $p(\demographicParamVector)$,
expands out into its components and as a product over the \npairs{}
pairs of populations
\begin{equation}
    p(\demographicParamVector) =
    \prod_{i=1}^{\npairs{}}
    p(\ancestralTheta{i})
    p(\descendantTheta{1}{i})
    p(\descendantTheta{2}{i})
    p(\bottleScalar{1}{i})
    p(\bottleScalar{2}{i})
    p(\bottleTime{i})
    p(\migrationRate{i}).
    \label{eq:demographicPrior}
\end{equation}
The priors for the demographic parameters are:
$\ancestralTheta{} \sim Gamma(\gammaShape{\ancestralTheta{}},
\gammaScale{\ancestralTheta{}})$,
$\descendantTheta{1}{} \sim Gamma(\gammaShape{\descendantTheta{}{}},
\gammaScale{\descendantTheta{}{}})$,
$\descendantTheta{2}{} \sim Gamma(\gammaShape{\descendantTheta{}{}},
\gammaScale{\descendantTheta{}{}})$,
$\bottleScalar{1}{} \sim Beta(\betaA{\bottleScalar{}{}},
\betaB{\bottleScalar{}{}})$,
$\bottleScalar{2}{} \sim Beta(\betaA{\bottleScalar{}{}},
\betaB{\bottleScalar{}{}})$,
$\bottleTime{} \sim U(0, 1)$,
and
$\migrationRate{} \sim Gamma(\gammaShape{\migrationRate{}},
\gammaScale{\migrationRate{}})$.
\end{linenomath}

\subsubsection*{Priors on divergence models}
\begin{linenomath}
The prior term for the vector of divergence times for each of
the \npairs{} pairs of populations can be expanded as
\begin{equation}
    p(\divTimeMapVector) = p(\divTimeIndexVector)p(\divTimeVector \given \divTimeIndexVector),
    \label{eq:divModelPrior}
\end{equation}
where \divTimeVector is an ordered set of unique divergence time parameters
$\{\divTime{1}, \ldots, \divTime{\divTimeNum}\}$ whose length
\divTimeNum can range from 1 to \npairs{},
and \divTimeIndexVector is vector of indices of divergence time parameters 
$(\divTimeIndex{1}, \ldots, \divTimeIndex{\npairs{}})$
that map the divergence time in \divTimeVector to each of the \npairs{}
pairs of populations.
Thus, \divTimeMapVector is the result of applying the mapping function
\begin{equation}
    f(\divTimeVector, \divTimeIndexVector, i) = \divTime{\divTimeIndex{i}}
    \label{eq:divTimeMapFunction}
\end{equation}
to each population pair $i$, such that
$\divTimeMapVector = (\divTimeMap{1} = f(\divTimeVector, \divTimeIndexVector,
1), \ldots, \divTimeMap{\npairs{}} = f(\divTimeVector, \divTimeIndexVector,
\npairs{}))$.
\end{linenomath}

Biologically speaking, \divTimeVector contains the times of divergence events,
the length of which \divTimeNum is the number of divergence events shared across
the \npairs{} pairs of populations.
For example, if \divTimeVector contains a single divergence time parameter
\divTime{1}, all \npairs{} pairs of populations are constrained to diverge at
this time (i.e., \divTimeIndexVector would contain the index 1 repeated
\npairs{} times, and \divTimeMapVector would contain the value \divTime{1}
repeated \npairs{} times), whereas if it contains \npairs{} divergence time
parameters, the model is fully generalized to allow all of the pairs to diverge
at unique times.

\begin{linenomath}
Each \divTime{} within \divTimeVector is \iid as $\divTime{} \sim
Gamma(\gammaShape{\divTime{}}, \gammaScale{\divTime{}})$.
Thus, given the number of unique divergence time classes in
\divTimeIndexVector, this determines the probability of prior term
$p(\divTimeVector \given \divTimeIndexVector)$
The divergence time parameters are in coalescent units relative to the size of
a constant reference population, which we denote \myTheta{C}, that is equal to
the expectation of the prior on the size of the descendant populations
\begin{equation}
    \myTheta{C} = E(\descendantTheta{}{}).
    \label{eq:thetaC}
\end{equation}
Given the size of the descendant populations are \iid as
$\descendantTheta{}{} \sim Gamma(\gammaShape{\descendantTheta{}{}},
\gammaScale{\descendantTheta{}{}})$,
this becomes
\begin{equation}
    \myTheta{C} = \gammaShape{\descendantTheta{}{}}\gammaScale{\descendantTheta{}{}}.
    \label{eq:thetaCGamma}
\end{equation}
The \divTime parameters are then in units $\myTheta{C}/\mutationRate$
generations, which we denote as \globalcoalunit generations.
Thus, each \divTime within \divTimeVector is proportional to time and
can be converted to the number of generations of the reference population,
which we denote \divTime{G_C}, by assuming a mutation rate multiplying by
the effective size of the reference population
\begin{equation}
    \divTime{G_C} = \divTime \times \frac{
        \gammaShape{\descendantTheta{}{}}\gammaScale{\descendantTheta{}{}}}
        {\mutationRate}.
    \label{eq:divTimeGenerations}
\end{equation}
Thus, for each of the divergence times in \divTimeVector to be on the same
scale, and thus comparable, the relative mutation rates among the pairs of
populations are assumed to be fixed and known according the user-provided
values in \mutationRateScalarConstantVector.
\end{linenomath}

\begin{linenomath}
As described by \citet{Oaks2012}, to get the divergence times in units
proportional to the expected number of mutations, \divTimeScaled{}{}, we must
scale them by the realized population size for locus $j$ of population-pair $i$ 
\begin{equation}
    \divTimeScaled{i}{j} = \divTimeMap{i} \times \frac{\myTheta{C}}{
        \descendantThetaMean{i} \ploidyScalar{i}{j}},
    \label{eq:divTimeScaled}
\end{equation}
where \descendantThetaMean{i} is the mean of \descendantTheta{1}{} and
\descendantTheta{2}{} for pair $i$.
This gives us the vector of scaled divergence times
$\divTimeScaledVector = (\divTimeScaled{1}{1}, \ldots,
\divTimeScaled{\npairs{}}{\nloci{\npairs{}}})$.
\end{linenomath}


\begin{linenomath}
As for the prior term $p(\divTimeMapVector)$,
the total sample space of ordered realizations of \divTimeMapVector is all the
possible partitions of \npairs{} elements into 1 to \npairs{} categories.
The total number of possible partitions is a sum of the Stirling numbers of
the second kind over all possible number of categories \divTimeNum
\begin{equation}
    B_{\npairs{}}=\sum_{\divTimeNum=1}^{\npairs{}} \left[
    \frac{1}{\divTimeNum!} \sum_{j=0}^{\divTimeNum-1} (-1)^{j}
    \binom{\divTimeNum}{j} (\divTimeNum-j)^{\npairs{}} \right],
    \label{eq:bell}
\end{equation}
which is the Bell Number \citep{Bell1934}.
The original \msb model only samples over the unordered realizations of
\divTimeIndexVector, such that the sample space is reduced to all the possible
integer partitions of \npairs{} \citep{Oaks2012,Huang2011,OeisPartitionNumber,
    OeisPartitionTriangle,Malenfant2011}.
We denote the set of all possible integer partitions of \npairs{} as
\integerPartitionSet{\npairs{}} and the length of that set as
\integerPartitionNum{\npairs{}}.
The advantages, disadvantages, and justification of ignoring the order
of \divTimeIndexVector is discussed in detail below.
\end{linenomath}

\begin{linenomath}
We implement two prior probability distributions over the space
of all possible discrete divergence models (\divTimeIndexVector).
The first simply gives all possible unordered partitions of \npairs{} elements
equal probability
\begin{equation}
    p(\divTimeIndexVector) = \frac{1}{\integerPartitionNum{\npairs{}}},
    \label{eq:divModelPriorUniform}
\end{equation}
i.e., a discrete uniform prior over all the integer partitions of \npairs{}
(discrete divergence models).
We denote this prior as
$\divTimeIndexVector \sim \priorUniform$.
\end{linenomath}

The second prior we implement is based on the Dirichlet-process, which is a
stochastic process that groups elements into an unknown number of discrete
parameter classes \citep{Ferguson1973,Antoniak1974}.
The process is controlled by the concentration parameter \concentrationParam,
which determines how clustered the process will be.
We use the Dirichlet process to place a prior over all possible ordered
partitions of \npairs{} elements, which we denote as $\divTimeIndexVector \sim
\priorDPP{}$.
We use a hierarchical Bayesian approach and place a second-order prior
probability distribution (i.e., hyperprior) on \concentrationParam.  More
specifically, we use a gamma-distributed prior $\concentrationParam =
Gamma(\gammaShape{\concentrationParam}, \gammaScale{\concentrationParam})$,
where \gammaShape{\concentrationParam} and \gammaScale{\concentrationParam} are
specified by the user.

\begin{linenomath}
This provides a great deal of flexibility for specifying the prior uncertainty
regarding divergence models.
The \concentrationParam determines the prior probability that any two
pairs of populations $i$ and $j$ will be assigned to the same divergence time
parameter
\begin{equation}
    p(\divTimeIndex{i} = \divTimeIndex{j}) = \frac{1}{1 + \concentrationParam},
    \label{eq:dppPriorSameClass}
\end{equation}
and also the prior probability of the number of divergence time parameters
\begin{equation}
    p(\divTimeNum \given \concentrationParam, \npairs{}) = 
    \frac{\stirlingFirst{\npairs{}}{\divTimeNum} \concentrationParam^{\divTimeNum}}
    {\prod_{i=1}^{\npairs{}}(\concentrationParam + i - 1)},
    \label{eq:dppPriorNumClasses}
\end{equation}
where \stirlingFirst{\cdot}{\cdot} are the unsigned Stirling numbers of the
first kind.
Equations \ref{eq:dppPriorSameClass} and \ref{eq:dppPriorNumClasses} show that
smaller values of \concentrationParam will favor fewer divergence time
parameters, and thus more clustered models of divergence, whereas larger values
will favor more divergence time parameters, and thus less clustered models of
divergence.
\end{linenomath}

\subsection*{Differences between our model and the original \msb model}
\subsubsection*{The prior on divergence models}
One of the key differences between our model and that of \msb \citep{Huang2011}
is the prior distribution placed on divergence models.
As discussed in \citet{Oaks2012}, in \msb the only prior used for
\divTimeIndexVector is a combination of a discrete uniform prior over the
possible number of divergence events \divTimeNum from 1 to \npairs{} with a
multinomial distribution on the number of times each index of \divTimeVector
appears in \divTimeIndexVector, with the constraint that all \divTime
parameters are represented at least once (see Equation 2 of \citet{Oaks2012}).
We denote this prior used by \msb as $\divTimeIndexVector \sim \priorOld$.
\citet{Oaks2012} discuss how placing a uniform prior over the number of
divergence parameters (\divTimeNum here; \numt{} in \citet{Huang2011}) imposes
an odd U-shaped prior over discrete divergence models (\divTimeIndexVector; see
Figure 5B of \citet{Oaks2012}).
To avoid this, we place priors directly on the sample space of divergence
models, thus eliminating the parameter \numt{} from the model.
We introduce two priors on divergence models:
(1) a prior that is uniform over all unordered divergence models, and
(2) a Dirichlet-process prior on all ordered divergence models.
The latter provides the user with a great deal of flexibility in
expressing their prior beliefs about models of divergence.

\subsubsection*{Estimating ordered divergence models}
As mentioned above, \msb samples over unordered divergence models
(i.e., unordered partitions of the \npairs{} pairs of populations).
That is, the identity of each population pair, and all the information
associated with it, is discarded.
In our implementation, inference can be done on either unordered or ordered
models of divergence.
This is discussed in more detail in the description of the ABC implementation
below.

\subsubsection*{The priors on nuisance parameters}
Following the recommendations of \citet{Oaks2012}, we have replaced the use of
inappropriate, continuous uniform distributions for priors on many of the
model's parameters (\divTime{}, \ancestralTheta{}, \descendantTheta{1}{},
\descendantTheta{2}{}, \bottleScalar{1}{}, \bottleScalar{2}{},
\recombinationRate, \migrationRate{}) with more flexible parametric
distributions from the exponential family.
We introduce gamma-distributed priors for rate parameters that have a sample
space of all positive real numbers (\divTime{}, \ancestralTheta{},
\descendantTheta{1}{}, \descendantTheta{2}{}, \recombinationRate,
\migrationRate{}), and beta-distributed priors for parameters that are
proportions bounded by zero and one (\bottleScalar{1}{} and
\bottleScalar{2}{}).
Not only do these priors have nice conjugacy properties, but they also provide
the user with much greater flexibility in expressing the prior uncertainty
regarding the parameters of the model.

Another distinction between our model and that of \msb, is the prior on the
sizes of the descendant populations of each pair.
As described by \citet{Oaks2012}, \msb uses the joint prior
\begin{equation}
    \descendantTheta{1}{}, \descendantTheta{2}{} \sim
    Dirichlet(1,1) \times 2 \times U(\uniformMin{\myTheta{}},
    \uniformMax{\descendantTheta{}{}}),
    \label{eq:jointThetaPrior}
\end{equation}
such that the user-specified uniform prior on descendant population
size is a prior on the \emph{mean} size of the two descendant
populations of each pair.
Under our model, the sizes of the descendant populations of each
pair are \iid as
$\descendantTheta{1}{} \sim Gamma(\gammaShape{\descendantTheta{}{}},
\gammaScale{\descendantTheta{}{}})$
and
$\descendantTheta{2}{} \sim Gamma(\gammaShape{\descendantTheta{}{}},
\gammaScale{\descendantTheta{}{}})$.
This relaxes the assumption that the sizes of the two descendant populations
are interdependent and negatively correlated.

\subsubsection*{Flexibility in parameterizing the model}
We also provide the user with the ability to control the richness of
the model.
For the \myTheta{} parameters, the model can be fully generalized to
allow each population pair to have three parameters:
\ancestralTheta{}, \descendantTheta{1}{}, and \descendantTheta{2}{}.
Furthermore, any model of \myTheta{} parameters nested within this
general model can also be specified, including the most restricted model
where the ancestral and descendant populations of each pair share
a single \myTheta{} parameter.

We also allow the user to eliminate the parameters associated with
the post-divergence bottlenecks in the descendant populations of
each pair
(\bottleTime{}, \bottleScalar{1}{}, and \bottleScalar{2}{}),
which constrains the descendant populations to be of
constant size from present back to the divergence event.
Also, rather than eliminate the bottleneck parameters, the user
can constrain \bottleScalar{1}{} and \bottleScalar{2}{} to be
equal to remove one free parameter from the model.

Overall, our implementation allows the user to specify a model that has as many
as seven parameters per population pair
(\ancestralTheta{}, \descendantTheta{1}{}, \descendantTheta{2}{},
\bottleTime{}, \bottleScalar{1}{}, \bottleScalar{2}{}, and
\migrationRate{})
or as few as one parameter per pair
(\myTheta{}),
in addition to the $\popSampleSize{i}{} - 1$ coalescence-time parameters.

\subsubsection*{Time scale}
As described above, in our model divergence times are in units of
$\myTheta{C}/\mutationRate$ generations, where \myTheta{C} is the expectation
of the prior on descendant-population size.
As described by \citet{Oaks2012}, in \msb, \myTheta{C} is half of the upper
limit of the continuous uniform prior on the mean of the descendant-population
sizes.

\subsection*{ABC estimation of the posterior}
\subsubsection*{Sampling from the prior}
To estimate the approximate posterior of Equation \ref{eq:approxModelCompact},
we use an ABC rejection algorithm.
The first step of this algorithm entails collecting a random sample of
parameters values from the joint prior and their associated summary
statistics.
Each sample is generated by
(1) drawing values of all the model's parameters, which we denote \hpvector{},
from their respective prior distributions;
(2) rescaling the divergence times
$\divTimeMapVector = (\divTimeMap{1}, \ldots, \divTimeMap{\npairs{}})$
from units proportional to time to units proportional to the expected number
of mutations via Equation \ref{eq:divTimeScaled} to get 
$\divTimeScaledVector = (\divTimeScaled{1}{1}, \ldots,
\divTimeScaled{\npairs{}}{\nloci{\npairs{}}})$;
(3) simulating gene trees $\geneTreeVector = (\geneTree{1}{1}, \ldots, 
\geneTree{\npairs{}}{\nloci{\npairs{}}})$
for each locus of each population pair by drawing coalescent times from
a multi-population Kingman-coalescent model given the demographic parameters;
(4) simulating sequences alignments 
$\alignmentVector = (\alignment{1}{1}, \ldots, \alignment{\npairs{}}{\nloci{\npairs{}}})$
along the gene trees under the
\hky substitution parameters
$\hkyModelVector = (\hkyModel{1}{1}, \ldots, \hkyModel{\npairs{}}{\nloci{\npairs{}}})$
that have the same number of sequences and sequence lengths as the observed
dataset;
(5) calculating population genetic summary statistics
$\ssVector{} = (\alignmentSS{1}{1}, \ldots, \alignmentSS{\npairs{}}{\nloci{\npairs{}}})$
from the simulated sequence alignments (these are the same statistics
calculated from the observed alignments, \ssVectorObs{});
and (6) reducing the summary statistics to the means across loci for each
population pair to get
$\ssVector{} = (\alignmentSS{1}{}, \ldots, \alignmentSS{\npairs{}}{})$, which is
the same summary statistic vector estimated from the observed data \ssVectorObs.
After repeating this procedure \numPriorSamples times, we obtain a random
sample of parameter vectors
$\paramSampleMatrix = (\paramSampleVector{1}, \ldots, \paramSampleVector{\numPriorSamples})$
from the model prior and there associated vectors of summary statistics
$\ssMatrix = (\ssVector{1}, \ldots, \ssVector{\numPriorSamples})$.

\subsubsection*{Ordering of taxon-specific summary statistics}
As eluded to in the model description, \msb does not maintain the order of the
taxon-specific summary statistics \alignmentSS{}{} within each \ssVector{}.
Rather, they, along with the observed summary statistics, are re-ordered by
descending values of average pairwise differences between the descendant
populations \citep[$\pi_b$;][]{NeiLi1979,Huang2011}.
This has the advantage of reducing the sample space of the number of discrete
divergence models \divTimeMapVector, but there are at least two disadvantages.
First, additional information in the data is lost.
By discarding the identity of the \npairs{} pairs of populations, all
pair-specific information about the amount of data (e.g., the number gene
copies collected from each of the populations [\popSampleSize{1}{} and
\popSampleSize{2}{}], the number of loci, and the length of the loci), and the
taxon- and locus-specific parameters (\hkyModel{}{},
\mutationRateScalarConstant{}{}, \ploidyScalar{}{}, and
\locusMutationRateScalar{}) is lost.
Second, the results are more difficult to interpret, because they can be no
longer directly associated to the taxa under study.

The original descriptions of the \msb model claim that this re-ordering is
justified by the fact that of $\pi_b$ (and other summary statistics) are
unrelated to the sample sizes \popSampleSize{1}{} and \popSampleSize{2}{} of
each pair and are thus exchangeable \citet{Hickerson2006,Huang2011}.
This is actually incorrect for two of reasons.
First, the expectation of $\pi_b$ is not independent of samples sizes.
If there are more than one coalescent events in the ancestor, which is expected
to be common on phylogeographic timescales, more samples will increase the
probability of capturing these deeper events, and thus affect the average
pairwise differences between the descendant populations.
Also, other statistics that estimate gross diversity (e.g., $\pi$ and
$\theta_W$) are clearly not independent of sample size.
Second, for variables to be exchangeable, they do not need to be independent,
but their marginal distributions must be the same (i.e., they must be
identically distributed).
The simulated alignments and their summary statistics are not identically
distributed because of differing sample sizes \emph{and} taxon- and
locus-specific parameters \hkyModel{}{}, \mutationRateScalarConstant{}{}, and
\ploidyScalar{}{}.

Thus, the theoretical basis for this reshuffling is questionable.
It may be justifiable as an additional coarsening of the data,
by removing the information associated with the identity of the
population pairs.
However, we do not provide a formal proof that this re-ordering of the pairs
does not introduce bias.
One can imagine situations in which the sampling intensity (i.e., the
number of gene copies, loci, and locus length) is highly skewed across
pairs and/or there is large heterogeneity in mutational processes
(e.g., \hkyModel{}{}, \mutationRateScalarConstant{}{}) among the pairs.
In such cases it seems possible that discarding this information could
cause bias.
Furthermore, given that part of the motivation for re-ordering by $\pi_b$ is to
minimize Euclidean distances between simulated datasets in which the true model
has a single divergence event, and this reordering increases the model's
tendency to infer a single divergence event \citep{Huang2011}, it seems
possible that this approach could be biasing the method \citet{Oaks2012}.

To maintain compatibility and comparability with \msb we maintain
the re-ordering of taxon-specific summary statistics by $\pi_b$, but
we also allow the order to be maintained.
This allows the estimation of ordered divergence models.

\subsubsection*{Obtaining an approximate posterior from the prior samples}
We use a rejection algorithm to retain an approximate posterior sample of
\paramSampleVector{} from the prior sample
$\paramSampleMatrix = (\paramSampleVector{1}, \ldots, \paramSampleVector{\numPriorSamples})$.
First, the observed summary statistics \ssVectorObs, and the summary statistics
of the prior samples 
$\ssMatrix = (\ssVector{1}, \ldots, \ssVector{\numPriorSamples})$,
are standardized using the means and standard deviations of the statistics from
the prior sample (i.e., the prior mean is subtracted from each statistic, and then
it is divided by the prior standard deviation).
After all statistics are standardized, the Euclidean distance between
the \ssVectorObs and each \ssVector{} within \ssMatrix is calculated.
The samples that fall within a range of tolerance \tol around \ssVectorObs
are retained.
The range of tolerance is determined by specifying the number of desired
posterior samples to be retained.
Post-hoc adjustment of the posterior sample can also be performed with a number
of regression techniques \citep{Beaumont2002,Blum2009,Leuenberger2010}.
For our analyses, we use the general linear model (GLM) regression adjustment
\citet{Leuenberger2010} as implemented in \abctoolbox
\citep[v1.1;][]{ABCtoolbox}, which \citet{Oaks2012} showed performed very
similarly to weighted local-linear regression and multinomial logistic
regression adjustments \citep{Beaumont2002} for \msb posteriors.


\subsection*{Assessing model-choice behavior and robustness}
Following the simulation-based approach of \citet{Oaks2012}, we characterize
the behavior of several models under the ideal conditions where the
data are generated from parameters drawn from the same prior distributions used
for analysis (i.e., the prior is correct).
We selected four model priors for these analyses (Table~\ref{tabPriors}):
(1) A model to represent the original \msb model, \modelOld, with
priors
$\divTimeIndexVector \sim \priorOld$,
$\divTime{} \sim U(0,10)$,
$\ancestralTheta{} \sim U(0, 0.05)$,
and
$\descendantThetaMean{} \sim U(0, 0.05)$;
(2) a Dirichlet-process prior model, \modelDPP, with priors
$\divTimeIndexVector \sim \priorDPP{\sim Gamma(2,2)}$,
$\divTime{} \sim Exp(0.3464)$,
$\ancestralTheta{} \sim Exp(40)$,
and
$\descendantTheta{}{} \sim Exp(40)$;
(3) a model with uniform prior probability over unordered divergence models,
\modelUniform, with priors
$\divTimeIndexVector \sim \priorUniform$,
$\divTime{} \sim Exp(0.3464)$,
$\ancestralTheta{} \sim Exp(40)$,
and
$\descendantTheta{}{} \sim Exp(40)$;
and
(4) a model with the \msb prior on unordered divergence models, but with
exponential priors on nuisance parameters,
\modelUshaped, with priors
$\divTimeIndexVector \sim \priorOld$,
$\divTime{} \sim Exp(0.3464)$,
$\ancestralTheta{} \sim Exp(40)$,
and
$\descendantTheta{}{} \sim Exp(40)$.
We selected the exponential prior on divergence time used in models \modelDPP,
\modelUniform, and \modelUshaped to have the same variance as the
uniform prior in model \modelOld.
We selected the exponential prior on population size used in models \modelDPP,
\modelUniform, and \modelUniform to have the same mean as the uniform prior in
model \modelOld, so that all four models have the same \myTheta{C} and thus the
same units of time.
All of the models were the same in other respects, with three free \myTheta{}
parameters for each population pair, two uniformly distributed ($beta(1,1)$)
\bottleScalar{}{} parameters per pair, no migration, no recombination,
and unordered divergence models.
For all of our simulations, we used a simulated data structure of eight
population pairs, with a single 1000 base-pair locus sampled from 10
individuals from each population.

For each of the four models, we generated $1\e6$ samples from the prior, and
simulated 50,000 pseudo-replicate datasets, also drawn from the prior.
We then analyzed each of the replicate datasets using the, retaining a
posterior sample from its respective prior.
A GLM-regression adjusted posterior was also estimated from each of the
posterior samples \citep{Leuenberger2010}.
To assess the robustness of each of the four models, we also analyzed the
pseudo-replicate datasets simulated under the other three models.
Overall, for each model, we produced 200,000 posterior estimates,
50,000 from the replicate datasets simulated under that model,
and 150,000 estimated from the replicate datasets simulated under the
other three models.

For each set of 50,000 simulated datasets, we used the posterior estimates
assess each model's model-choice behavior.
We did this by assigning the 50,000 estimates of the posterior probability
of one divergence event to 20 bins of width 0.05, and plotted
the estimated posterior probability of each bin against the proportion of
replicates in that bin with a true value consistent with one divergence
event \cite{Huelsenbeck2004,Oaks2012}.
We did this using two criteria for the one divergence model:
(1) the number of divergence time parameters ($\divTimeNum = 1$) and
(2) the dispersion index of divergence times ($\divTimeDispersion < 0.01$).
We used the one-divergence model to assess model-choice behavior, because
it is often of biogeographic interest and is easily comparable among
the three different priors used on divergence models.

In addition to the four models above, we also assessed the behavior of a model
with ordered divergence models (i.e., the order of the taxon-specific summary
statistic vectors were maintained for the observed and simulated datasets).
For this, we used a model with identical priors as \modelDPP, but that samples
over ordered divergence models.
We denote this model as \modelDPPOrdered.
We generated $1\e6$ prior samples and 50,000 pseudo-replicate datasets, and
analyzed them as above.
We were not able to analyze the replicate datasets of the other models under
the ordered model, because the identity of the population pairs is not
contained in the simulations of the other models.

\subsection*{Assessing power}
We evaluated the power of the same four models (Table~\ref{tabPriors}) to
detect random variation in divergence times using methods similar to
\citet{Oaks2012}.
For all of our power simulations, we used a simulated data structure identical
to that of the empirical dataset of Philippine vertebrates analyzed by
\citet{Oaks2012}, which consists of 22 pairs of populations.
For each of the four models, we generated $2\e6$ samples from the prior.
We then generated pseudo-observed datasets from three series of models.
One series of models, which we denote \powerSeriesOld, is identically
distributed as \modelOld except that the divergence times for each of the 22
pairs of populations are randomly drawn from a series of uniform distributions,
$U(0, \divt{max})$, where \divt{max} was set to: 0.2, 0.4, 0.6, 0.8, 1.0, and
2.0, in \globalcoalunit generations.
A second series of models, \powerSeriesUniform, are identically distributed as
\modelUniform except that the 22 divergence times are randomly drawn from the
same series of uniform priors as above.
The third series of models, \powerSeriesExp, is also identically
distributed as \modelUniform except that the 22 divergence times are randomly
drawn from a series of of exponential distributions: $Exp(17.3205)$,
$Exp(8.6603)$, $Exp(5.7735)$, $Exp(4.33013)$, $Exp(3.4641)$, and $Exp(1.7321)$.
These exponential distributions have the same variance as their uniform
counterparts in the first two series of models.

For each of the six models in each of the three series of models, we simulated
1000 pseudo-replicate datasets (18,000 datasets in total).
We then analyzed each replicate dataset under all four prior models
(Table~\ref{tabPriors}), producing 72,000 posterior estimates, each with 1000
samples.
We also estimated a GLM-regression adjusted posterior from each of the
posterior samples \citep{Leuenberger2010}.

\section*{Results}
\subsection*{Validation analyses: Estimation accuracy}
In terms of estimating summary statistics of model parameters (\divTimeNum,
\divTimeDispersion, and \divTimeMean), the \modelDPP performs similarly when
applied to datasets generated under all four models of Table \ref{tabPriors}
(Figs.\
\labelcref{figValidationAccuracyDPPDPP,figValidationAccuracyUniformDPP,figValidationAccuracyOldDPP,figValidationAccuracyUshapedDPP}).
The same is true for models \modelUniform (Figs.\
\labelcref{figValidationAccuracyDPPUniform,figValidationAccuracyUniformUniform,figValidationAccuracyOldUniform,figValidationAccuracyUshapedUniform})
and \modelUshaped (Figs.\
\labelcref{figValidationAccuracyDPPUshaped,figValidationAccuracyUniformUshaped,figValidationAccuracyOldUshaped,figValidationAccuracyUshapedUshaped}).
All three of the models with exponential priors on nuisance parameters
(\modelDPP, \modelUniform, and \modelUshaped) perform well when applied
to the data generated under the original \msb model, \modelOld (Figs.\
\labelcref{figValidationAccuracyOldDPP,figValidationAccuracyOldUniform,figValidationAccuracyOldUshaped}).
The \modelOld model also performed well on its own datasets (Figure
\ref{figValidationAccuracyOldOld}), but performed poorly when applied to the
data generated under the other three models (Figs.\
\labelcref{figValidationAccuracyDPPOld,figValidationAccuracyUniformOld,figValidationAccuracyUshapedOld}).
Thus, the newly implemented models display greater robustness than
the original model.

Posterior adjustment with GLM regression does improve the estimation
accuracy for the continuous variables \divTimeDispersion and \divTimeMean,
however, this is not always true for estimating the discrete variable
\divTimeNum (Figs.\
\labelcref{figValidationAccuracyDPPDPP,figValidationAccuracyUniformDPP,figValidationAccuracyOldDPP,figValidationAccuracyUshapedDPP,figValidationAccuracyDPPUniform,figValidationAccuracyUniformUniform,figValidationAccuracyOldUniform,figValidationAccuracyUshapedUniform,figValidationAccuracyDPPUshaped,figValidationAccuracyUniformUshaped,figValidationAccuracyOldUshaped,figValidationAccuracyUshapedUshaped,figValidationAccuracyDPPOld,figValidationAccuracyUniformOld,figValidationAccuracyUshapedOld,figValidationAccuracyOldOld}).

\subsection*{Validation analyses: Model-choice accuracy}
The \msb model, and our modifications of it, is a model-choice method
with the primary purpose of estimating the probabilities of models
of divergence across taxa.
Thus, it is critical to assess the method's ability to accurately
estimate the posterior probabilities of divergence models.
Our results demonstrate that the unadjusted estimates of
divergence models are generally more accurate than the regression
adjusted estimates, especially when using $\divTimeDispersion < 0.01$
to assess the probability of the one divergence model (Figs.\
\labelcref{figValidationModelChoiceDPPDPP,figValidationModelChoiceUniformDPP,figValidationModelChoiceOldDPP,figValidationModelChoiceUshapedDPP,figValidationModelChoiceDPPUniform,figValidationModelChoiceUniformUniform,figValidationModelChoiceOldUniform,figValidationModelChoiceUshapedUniform,figValidationModelChoiceDPPUshaped,figValidationModelChoiceUniformUshaped,figValidationModelChoiceOldUshaped,figValidationModelChoiceUshapedUshaped,figValidationModelChoiceDPPOld,figValidationModelChoiceUniformOld,figValidationModelChoiceUshapedOld,figValidationModelChoiceOldOld}).
Thus, we will focus our discussion of the results on the unadjusted estimates.

The model-choice behavior of the \modelDPP is relatively accurate when applied
to datasets generated under models \modelDPP, \modelUniform, and \modelOld
(Figs.\
\labelcref{figValidationModelChoiceDPPDPP,figValidationModelChoiceUniformDPP,figValidationModelChoiceOldDPP}).
It is less accurate and tends to underestimate the probability of the
one-divergence model when applied to the data generated under \modelUshaped
(Figure \ref{figValidationModelChoiceUshapedDPP}).
The \modelUniform model performs almost identically as \modelDPP in
terms of model-choice accuracy (Figs.\
\labelcref{figValidationModelChoiceDPPUniform,figValidationModelChoiceUniformUniform,figValidationModelChoiceOldUniform,figValidationModelChoiceUshapedUniform}).

The original \msb model \modelOld performs reasonably well when applied
to its own datasets (Figure \ref{figValidationModelChoiceOldOld}), but
it performs poorly when applied to data generated under any of the other
models (Figs.\
\labelcref{figValidationModelChoiceDPPOld,figValidationModelChoiceUniformOld,figValidationModelChoiceUshapedOld}).
In these cases the \modelOld model is strongly biased towards over-estimating
the posterior probability of the one-divergence model, especially when the
divergence models are not distributed under its U-shaped prior (Figs.\
\labelcref{figValidationModelChoiceDPPOld,figValidationModelChoiceUniformOld}).
The other model with the U-shaped prior on divergence models, but exponential
priors on nuisance parameters (\modelUshaped), performs similarly to \modelOld
in that it performs well when applied to its own data, but overestimates
the probability of the one-divergence model when applied to data generated
by the other models (Figs.\
\labelcref{figValidationModelChoiceDPPUshaped,figValidationModelChoiceUniformUshaped,figValidationModelChoiceUshapedUshaped,figValidationModelChoiceUshapedUshaped}).
However, the bias toward over-estimating the probability of the one-divergence
model is stronger in the \modelOld model than \modelUshaped.

Overall, the result suggest that the \modelDPP and \modelUniform models are
relatively robust in terms of model-choice accuracy, and when model violations
do cause them to be biased, they tend to under-estimate the probability of
the biogeographically interesting model of a single divergence event.
In contrast, the \modelOld model is very sensitive to model violations,
and strongly over-estimates the one-divergence model whenever the model
is misspecified.
Furthermore, the results suggest that using exponentially distributed priors on
nuisance parameters rather than uniform priors helps the \modelUshaped model
perform better than \modelOld, but it is still hindered by the Ushaped prior on
divergence models and tends to over-estimate the probability of the
one-divergence model whenever there are violations of the mode.


\subsection*{Validation analyses: Ordered divergence models}
Our results show that the model estimating ordered models of divergence
\modelDPPOrdered performs similarly to its counterpart sampling over
unordered models \modelDPP when the prior is correct (Figs.\
\labelcref{figValidationAccuracyDPPOrderedDPPOrdered,figValidationModelChoiceDPPOrderedDPPOrdered}).

\subsection*{Power analyses: Estimation accuracy}
All of the models we evaluated (Table \ref{tabPriors}) struggled to estimate
the dispersion index of divergence times \divTimeDispersion regardless of which
of the three series of models (Table \ref{tabPowerModels}) the data were
generated under (Figs.\
\labelcref{figPowerAccuracyExpDPP,figPowerAccuracyExpUniform,figPowerAccuracyExpOld,figPowerAccuracyExpUshaped,figPowerAccuracyUniformDPP,figPowerAccuracyUniformUniform,figPowerAccuracyUniformOld,figPowerAccuracyUniformUshaped,figPowerAccuracyOldDPP,figPowerAccuracyOldUniform,figPowerAccuracyOldOld,figPowerAccuracyOldUshaped}).
When the divergence times of the 22 population pairs are randomly drawn from a
series of exponential priors (\powerSeriesExp), the \modelDPP model is the
best estimator of \divTimeDispersion, followed by \modelUshaped (figs.\
\labelcref{figPowerAccuracyExpDPP,figPowerAccuracyExpUniform}
The \modelOld model is strongly biased toward underestimating
\divTimeDispersion, estimating values of zero for most of the replicates across
all the data models of \powerSeriesExp (Figure \ref{figPowerAccuracyExpOld}).
The results of the \modelUshaped model are intermediate between those of
\modelOld and the better performing models \modelDPP and \modelUniform
(Figure \ref{figPowerAccuracyExpUshaped}).

When the true divergence times are randomly drawn from a series of uniform
priors (\powerSeriesUniform), all of the models poorly estimate
\divTimeDispersion (Figs.\
\labelcref{figPowerAccuracyUniformDPP,figPowerAccuracyUniformUniform,figPowerAccuracyUniformOld,figPowerAccuracyUniformUshaped}).
The \modelDPP and \modelUniform models tend to over-estimate the variance in
divergence times (Figs.\
\labelcref{figPowerAccuracyUniformDPP,figPowerAccuracyUniformUniform}), whereas
the \modelOld model, again, underestimates \divTimeDispersion, estimating
values of zero for most replicates across all the data models of
\powerSeriesUniform (Figure \ref{figPowerAccuracyUniformOld}).
Again, the performance of the \modelUshaped model is intermediate between the
\modelOld and \modelDPP/\modelUniform models (Figure
\ref{figPowerAccuracyUniformUshaped}).
This pattern of results across the four models is very similar when applied
to data simulated under the series of models of \powerSeriesOld (Figs.\
\labelcref{figPowerAccuracyOldDPP,figPowerAccuracyOldUniform,figPowerAccuracyOldOld,figPowerAccuracyOldUshaped}).

\subsection*{Power analyses: model-choice}
There is a large amount of heterogeneity in estimating the number of divergence
events (\divTimeNum) both among the prior models, and across the different
series of data models (Table \ref{tabPowerModels}) (Figs.\
\labelcref{figPowerPsiExpDPP,figPowerPsiExpUniform,figPowerPsiExpOld,figPowerPsiExpUshaped,figPowerPsiUniformDPP,figPowerPsiUniformUniform,figPowerPsiUniformOld,figPowerPsiUniformUshaped,figPowerPsiOldDPP,figPowerPsiOldUniform,figPowerPsiOldOld,figPowerPsiOldUshaped}).
The \modelDPP model tends to infer highly clustered divergence models across
all three series of data models when the divergences are recent, but performs
the best of the four prior models  when divergences are random over a timescale
of about one to two coalescent units (Figs.\
\labelcref{figPowerPsiExpDPP,figPowerPsiUniformDPP,figPowerPsiOldDPP,}).
The \modelUniform model performs the best when divergences are random
over the most recent timescales, but tends to only infer a tight
cluster of \divTimeNum values even when divergences are random
over longer periods (Figs.\
\labelcref{figPowerPsiExpUniform,figPowerPsiUniformUniform,figPowerPsiOldUniform,}).
The \modelOld model performs the worst of the four prior models across
all three series of data models, inferring a single divergence event across
most of the 18,000 simulations (Figs.\
\labelcref{figPowerPsiExpOld,figPowerPsiUniformOld,figPowerPsiOldOld,}).
Even when the simulated data are identically distributed as the \modelOld model
except for the divergence times, the \modelOld is still strongly biased towards
a single event, whereas the \modelDPP model is the least likely to infer a
single event when applied to these data.
Using exponential priors on nuisance parameters does increase the power
of the \modelUshaped model compared \modelOld across all three series
of data models, but the U-shaped prior still prevents the model
from performing as well as the \modelDPP and \modelUniform models (Figs.\
\labelcref{figPowerPsiExpUshaped,figPowerPsiUniformUshaped,figPowerPsiOldUshaped,}).

The improved power of the new models are even more pronounced when looking at
estimates of the dispersion index of divergence times (\divTimeDispersion)
across the simulations (Figs.\
\labelcref{figPowerDispersionExpDPP,figPowerDispersionExpUniform,figPowerDispersionExpOld,figPowerDispersionExpUshaped,figPowerDispersionUniformDPP,figPowerDispersionUniformUniform,figPowerDispersionUniformOld,figPowerDispersionUniformUshaped,figPowerDispersionOldDPP,figPowerDispersionOldUniform,figPowerDispersionOldOld,figPowerDispersionOldUshaped}).
The \modelDPP and \modelUniform models perform similarly across all three
series of data models, inferring values of \divTimeDispersion consistent with
one divergence event ($\divTimeDispersion < 0.01)$ in almost none of the
replicates across all the simulations (Figs.\
\labelcref{figPowerDispersionExpDPP,figPowerDispersionExpUniform,figPowerDispersionUniformDPP,figPowerDispersionUniformUniform,figPowerDispersionOldDPP,figPowerDispersionOldUniform}).
The \modelOld model infers values consistent with a single divergence event in
most of the replicates across all the simulations (Figs.\
\labelcref{figPowerDispersionExpOld,figPowerDispersionUniformOld,figPowerDispersionOldOld}).
Using exponential priors on nuisance parameters greatly increases the power
of the \modelUshaped model relative to \modelOld, but it still has
less power than the models with DPP or uniform priors across
divergence models (Figs.\
\labelcref{figPowerDispersionExpUshaped,figPowerDispersionUniformUshaped,figPowerDispersionOldUshaped}).

When looking at the estimated posterior probability of the single-divergence
model across the power analyses, we also see the increased power of the
new models (Figs.\
\labelcref{figPowerPsiProbExpDPP,figPowerPsiProbExpUniform,figPowerPsiProbExpOld,figPowerPsiProbExpUshaped,figPowerPsiProbUniformDPP,figPowerPsiProbUniformUniform,figPowerPsiProbUniformOld,figPowerPsiProbUniformUshaped,figPowerPsiProbOldDPP,figPowerPsiProbOldUniform,figPowerPsiProbOldOld,figPowerPsiProbOldUshaped}).
The \modelDPP model estimates low posterior probability of
$\divTimeNum = 1$ across all of the simulations (Figs.\
\labelcref{figPowerPsiProbExpDPP,figPowerPsiProbUniformDPP,figPowerPsiProbOldDPP}).
The \modelDPP does infer strong support for one divergence as gauged by a Bayes
factor of greater than 10.
However, this is not that unexpected given the low prior probability of a
single divergence under this model.
Also, the Bayes factor calculations for the \modelDPP replicates are only
approximate; they are calculated base on the prior mean of the concentration
parameter \concentrationParam.

The \modelUniform model infers very low posterior probabilities for the
one-divergence model across all the simulations (Figs.\
\labelcref{figPowerPsiProbExpUniform,figPowerPsiProbUniformUniform,figPowerPsiProbOldUniform}).
The\modelOld model infers high posterior probabilities of a single divergence
for most replicates across all simulations (Figs.\
\labelcref{figPowerPsiProbExpOld,figPowerPsiProbUniformOld,figPowerPsiProbOldOld}).
Again, we see that the exponential priors on nuisance parameters greatly
increase power and result in lower estimates of the probability of
one divergence when comparing \modelUshaped to \modelOld (Figs.\
\labelcref{figPowerPsiProbExpUshaped,figPowerPsiProbUniformUshaped,figPowerPsiProbOldUshaped}).

Lastly, when we look at the estimated posterior probability of
\divTimeDispersion being consistent with one divergence parameter
($p(\divTimeDispersion < 0.01 | \ssSpace)$), we see the same pattern of model
behavior, with \modelDPP and \modelUniform inferring low probabilities across
all simulations, \modelOld inferring high probabilities, and \modelUshaped
inferring intermediate values (Figs.\
\labelcref{figPowerDispersionProbExpDPP,figPowerDispersionProbExpUniform,figPowerDispersionProbExpOld,figPowerDispersionProbExpUshaped,figPowerDispersionProbUniformDPP,figPowerDispersionProbUniformUniform,figPowerDispersionProbUniformOld,figPowerDispersionProbUniformUshaped,figPowerDispersionProbOldDPP,figPowerDispersionProbOldUniform,figPowerDispersionProbOldOld,figPowerDispersionProbOldUshaped}).

\section*{Acknowledgments}
We thank the National Science Foundation for supporting this work (DEB
1011423).
J.\ Oaks was also supported by the University of Kansas (KU) Office of Graduate
Studies, Society of Systematic Biologists, Sigma Xi Scientific Research
Society, KU Department of Ecology and Evolutionary Biology, and the KU
Biodiversity Institute.

\bibliography{../bib/references}

%% LIST OF FIGURES %%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\singlespacing

\renewcommand\listfigurename{Figure Captions}
\cftsetindents{fig}{0cm}{2.2cm}
\renewcommand\cftdotsep{\cftnodots}
\setlength\cftbeforefigskip{10pt}
\cftpagenumbersoff{fig}
\listoffigures


\end{linenumbers}

%% TABLES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\singlespacing

\begin{table}[htbp]
    \sffamily
    % \footnotesize
    \addtolength{\tabcolsep}{-0.08cm}
    \rowcolors{2}{}{myGray}
    %\captionsetup{font=footnotesize}
    \caption{The model priors evaluated in our simulation-based analyses.}
    \centering
    \begin{tabular}{ l l l l l }
        \toprule
        & \multicolumn{4}{c}{Priors} \\
        \cmidrule(){2-5}
        Model & \divTimeIndexVector & \divTime{} & \ancestralTheta{} & \descendantTheta{}{} \\
        \midrule
            \modelOld & $\divTimeIndexVector \sim \priorOld$
                      & $\divTime{} \sim U(0,10)$
                      & $\ancestralTheta{} \sim U(0, 0.05)$
                      & $\descendantThetaMean{} \sim U(0, 0.05)$ \\
            \modelDPP & $\divTimeIndexVector \sim \priorDPP{\sim Gamma(2,2)}$
                      & $\divTime{} \sim Exp(0.3464)$
                      & $\ancestralTheta{} \sim Exp(40)$
                      & $\descendantTheta{}{} \sim Exp(40)$ \\
            \modelUniform & $\divTimeIndexVector \sim \priorUniform$
                          & $\divTime{} \sim Exp(0.3464)$
                          & $\ancestralTheta{} \sim Exp(40)$
                          & $\descendantTheta{}{} \sim Exp(40)$ \\
            \modelUshaped & $\divTimeIndexVector \sim \priorOld$
                          & $\divTime{} \sim Exp(0.3464)$
                          & $\ancestralTheta{} \sim Exp(40)$
                          & $\descendantTheta{}{} \sim Exp(40)$ \\
        \bottomrule
    \end{tabular}
    \label{tabPriors}
\end{table}

\clearpage

\begin{table}[htbp]
    \sffamily
    % \footnotesize
    % \addtolength{\tabcolsep}{-0.08cm}
    \rowcolors{2}{}{myGray}
    %\captionsetup{font=footnotesize}
    \caption{The models we used to simulate pseudo-replicate datasets for
        assessing the power of the models in Table \ref{tabPriors}.}
    \centering
    \begin{tabular}{ l l l l l }
        \toprule
        & \multicolumn{4}{c}{Priors} \\
        \cmidrule(){2-5}
        Model series & \divTimeIndexVector & \divTime{} & \ancestralTheta{} & \descendantTheta{}{} \\
        \midrule
            \powerSeriesOld & $\divTimeNum = 22$
                            & $\divTime{} \sim U(0,0.2)$
                            & $\ancestralTheta{} \sim U(0, 0.05)$
                            & $\descendantThetaMean{} \sim U(0, 0.05)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim U(0,0.4)$
                            & $\ancestralTheta{} \sim U(0, 0.05)$
                            & $\descendantThetaMean{} \sim U(0, 0.05)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim U(0,0.6)$
                            & $\ancestralTheta{} \sim U(0, 0.05)$
                            & $\descendantThetaMean{} \sim U(0, 0.05)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim U(0,0.8)$
                            & $\ancestralTheta{} \sim U(0, 0.05)$
                            & $\descendantThetaMean{} \sim U(0, 0.05)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim U(0,1.0)$
                            & $\ancestralTheta{} \sim U(0, 0.05)$
                            & $\descendantThetaMean{} \sim U(0, 0.05)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim U(0,2.0)$
                            & $\ancestralTheta{} \sim U(0, 0.05)$
                            & $\descendantThetaMean{} \sim U(0, 0.05)$ \\
        \midrule
            \powerSeriesUniform & $\divTimeNum = 22$
                            & $\divTime{} \sim U(0,0.2)$
                            & $\ancestralTheta{} \sim Exp(40)$
                            & $\descendantTheta{}{} \sim Exp(40)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim U(0,0.4)$
                            & $\ancestralTheta{} \sim Exp(40)$
                            & $\descendantTheta{}{} \sim Exp(40)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim U(0,0.6)$
                            & $\ancestralTheta{} \sim Exp(40)$
                            & $\descendantTheta{}{} \sim Exp(40)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim U(0,0.8)$
                            & $\ancestralTheta{} \sim Exp(40)$
                            & $\descendantTheta{}{} \sim Exp(40)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim U(0,1.0)$
                            & $\ancestralTheta{} \sim Exp(40)$
                            & $\descendantTheta{}{} \sim Exp(40)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim U(0,2.0)$
                            & $\ancestralTheta{} \sim Exp(40)$
                            & $\descendantTheta{}{} \sim Exp(40)$ \\
        \midrule
            \powerSeriesExp & $\divTimeNum = 22$
                            & $\divTime{} \sim Exp(17.3205)$
                            & $\ancestralTheta{} \sim Exp(40)$
                            & $\descendantTheta{}{} \sim Exp(40)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim Exp(8.6603)$
                            & $\ancestralTheta{} \sim Exp(40)$
                            & $\descendantTheta{}{} \sim Exp(40)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim Exp(5.7735)$
                            & $\ancestralTheta{} \sim Exp(40)$
                            & $\descendantTheta{}{} \sim Exp(40)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim Exp(4.3301)$
                            & $\ancestralTheta{} \sim Exp(40)$
                            & $\descendantTheta{}{} \sim Exp(40)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim Exp(3.4641)$
                            & $\ancestralTheta{} \sim Exp(40)$
                            & $\descendantTheta{}{} \sim Exp(40)$ \\
                            & $\divTimeNum = 22$
                            & $\divTime{} \sim Exp(1.7321)$
                            & $\ancestralTheta{} \sim Exp(40)$
                            & $\descendantTheta{}{} \sim Exp(40)$ \\
        \bottomrule
    \end{tabular}
    \label{tabPowerModels}
\end{table}

\clearpage

%% FIGURES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage

%% Validation accuracy
\mFigure{../../validation/results/dpp/pymsbayes-results/plots/prior-dpp_prior-dpp_accuracy.pdf}{
    \validationAccuracyCaption{\modelDPP}{\modelDPP}
}{figValidationAccuracyDPPDPP}

\mFigure{../../validation/results/dpp/pymsbayes-results/plots/prior-dpp_prior-uniform_accuracy.pdf}{
    \validationAccuracyCaption{\modelDPP}{\modelUniform}
}{figValidationAccuracyDPPUniform}

\mFigure{../../validation/results/dpp/pymsbayes-results/plots/prior-dpp_prior-old_accuracy.pdf}{
    \validationAccuracyCaption{\modelDPP}{\modelOld}
}{figValidationAccuracyDPPOld}

\mFigure{../../validation/results/dpp/pymsbayes-results/plots/prior-dpp_prior-u-shaped_accuracy.pdf}{
    \validationAccuracyCaption{\modelDPP}{\modelUshaped}
}{figValidationAccuracyDPPUshaped}


\mFigure{../../validation/results/uniform/pymsbayes-results/plots/prior-uniform_prior-dpp_accuracy.pdf}{
    \validationAccuracyCaption{\modelUniform}{\modelDPP}
}{figValidationAccuracyUniformDPP}

\mFigure{../../validation/results/uniform/pymsbayes-results/plots/prior-uniform_prior-uniform_accuracy.pdf}{
    \validationAccuracyCaption{\modelUniform}{\modelUniform}
}{figValidationAccuracyUniformUniform}

\mFigure{../../validation/results/uniform/pymsbayes-results/plots/prior-uniform_prior-old_accuracy.pdf}{
    \validationAccuracyCaption{\modelUniform}{\modelOld}
}{figValidationAccuracyUniformOld}

\mFigure{../../validation/results/uniform/pymsbayes-results/plots/prior-uniform_prior-u-shaped_accuracy.pdf}{
    \validationAccuracyCaption{\modelUniform}{\modelUshaped}
}{figValidationAccuracyUniformUshaped}


\mFigure{../../validation/results/old/pymsbayes-results/plots/prior-old_prior-dpp_accuracy.pdf}{
    \validationAccuracyCaption{\modelOld}{\modelDPP}
}{figValidationAccuracyOldDPP}

\mFigure{../../validation/results/old/pymsbayes-results/plots/prior-old_prior-uniform_accuracy.pdf}{
    \validationAccuracyCaption{\modelOld}{\modelUniform}
}{figValidationAccuracyOldUniform}

\mFigure{../../validation/results/old/pymsbayes-results/plots/prior-old_prior-old_accuracy.pdf}{
    \validationAccuracyCaption{\modelOld}{\modelOld}
}{figValidationAccuracyOldOld}

\mFigure{../../validation/results/old/pymsbayes-results/plots/prior-old_prior-u-shaped_accuracy.pdf}{
    \validationAccuracyCaption{\modelOld}{\modelUshaped}
}{figValidationAccuracyOldUshaped}


\mFigure{../../validation/results/u-shaped/pymsbayes-results/plots/prior-u-shaped_prior-dpp_accuracy.pdf}{
    \validationAccuracyCaption{\modelUshaped}{\modelDPP}
}{figValidationAccuracyUshapedDPP}

\mFigure{../../validation/results/u-shaped/pymsbayes-results/plots/prior-u-shaped_prior-uniform_accuracy.pdf}{
    \validationAccuracyCaption{\modelUshaped}{\modelUniform}
}{figValidationAccuracyUshapedUniform}

\mFigure{../../validation/results/u-shaped/pymsbayes-results/plots/prior-u-shaped_prior-old_accuracy.pdf}{
    \validationAccuracyCaption{\modelUshaped}{\modelOld}
}{figValidationAccuracyUshapedOld}

\mFigure{../../validation/results/u-shaped/pymsbayes-results/plots/prior-u-shaped_prior-u-shaped_accuracy.pdf}{
    \validationAccuracyCaption{\modelUshaped}{\modelUshaped}
}{figValidationAccuracyUshapedUshaped}




%% Validation model choice
\mFigure{../../validation/results/dpp/pymsbayes-results/plots/prior-dpp_prior-dpp_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelDPP}{\modelDPP}
}{figValidationModelChoiceDPPDPP}

\mFigure{../../validation/results/dpp/pymsbayes-results/plots/prior-dpp_prior-uniform_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelDPP}{\modelUniform}
}{figValidationModelChoiceDPPUniform}

\mFigure{../../validation/results/dpp/pymsbayes-results/plots/prior-dpp_prior-old_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelDPP}{\modelOld}
}{figValidationModelChoiceDPPOld}

\mFigure{../../validation/results/dpp/pymsbayes-results/plots/prior-dpp_prior-u-shaped_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelDPP}{\modelUshaped}
}{figValidationModelChoiceDPPUshaped}


\mFigure{../../validation/results/uniform/pymsbayes-results/plots/prior-uniform_prior-dpp_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelUniform}{\modelDPP}
}{figValidationModelChoiceUniformDPP}

\mFigure{../../validation/results/uniform/pymsbayes-results/plots/prior-uniform_prior-uniform_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelUniform}{\modelUniform}
}{figValidationModelChoiceUniformUniform}

\mFigure{../../validation/results/uniform/pymsbayes-results/plots/prior-uniform_prior-old_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelUniform}{\modelOld}
}{figValidationModelChoiceUniformOld}

\mFigure{../../validation/results/uniform/pymsbayes-results/plots/prior-uniform_prior-u-shaped_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelUniform}{\modelUshaped}
}{figValidationModelChoiceUniformUshaped}


\mFigure{../../validation/results/old/pymsbayes-results/plots/prior-old_prior-dpp_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelOld}{\modelDPP}
}{figValidationModelChoiceOldDPP}

\mFigure{../../validation/results/old/pymsbayes-results/plots/prior-old_prior-uniform_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelOld}{\modelUniform}
}{figValidationModelChoiceOldUniform}

\mFigure{../../validation/results/old/pymsbayes-results/plots/prior-old_prior-old_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelOld}{\modelOld}
}{figValidationModelChoiceOldOld}

\mFigure{../../validation/results/old/pymsbayes-results/plots/prior-old_prior-u-shaped_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelOld}{\modelUshaped}
}{figValidationModelChoiceOldUshaped}


\mFigure{../../validation/results/u-shaped/pymsbayes-results/plots/prior-u-shaped_prior-dpp_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelUshaped}{\modelDPP}
}{figValidationModelChoiceUshapedDPP}

\mFigure{../../validation/results/u-shaped/pymsbayes-results/plots/prior-u-shaped_prior-uniform_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelUshaped}{\modelUniform}
}{figValidationModelChoiceUshapedUniform}

\mFigure{../../validation/results/u-shaped/pymsbayes-results/plots/prior-u-shaped_prior-old_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelUshaped}{\modelOld}
}{figValidationModelChoiceUshapedOld}

\mFigure{../../validation/results/u-shaped/pymsbayes-results/plots/prior-u-shaped_prior-u-shaped_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelUshaped}{\modelUshaped}
}{figValidationModelChoiceUshapedUshaped}


%% Validation ordered models
\mFigure{../../validation/no-sort/results/pymsbayes-results/plots/prior-dpp_prior-dpp_accuracy.pdf}{
    \validationAccuracyCaption{\modelDPPOrdered}{\modelDPPOrdered}
}{figValidationAccuracyDPPOrderedDPPOrdered}

\mFigure{../../validation/no-sort/results/pymsbayes-results/plots/prior-dpp_prior-dpp_mc_behavior.pdf}{
    \validationModelChoiceCaption{\modelDPPOrdered}{\modelDPPOrdered}
}{figValidationModelChoiceDPPOrderedDPPOrdered}



%% Power accuracy results
\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_dpp_power_accuracy_omega_median.pdf}{
    \powerAccuracyCaption{\powerSeriesExp}{\modelDPP}
}{figPowerAccuracyExpDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_uniform_power_accuracy_omega_median.pdf}{
    \powerAccuracyCaption{\powerSeriesExp}{\modelUniform}
}{figPowerAccuracyExpUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_old_power_accuracy_omega_median.pdf}{
    \powerAccuracyCaption{\powerSeriesExp}{\modelOld}
}{figPowerAccuracyExpOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_u-shaped_power_accuracy_omega_median.pdf}{
    \powerAccuracyCaption{\powerSeriesExp}{\modelUshaped}
}{figPowerAccuracyExpUshaped}


\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_dpp_power_accuracy_omega_median.pdf}{
    \powerAccuracyCaption{\powerSeriesUniform}{\modelDPP}
}{figPowerAccuracyUniformDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_uniform_power_accuracy_omega_median.pdf}{
    \powerAccuracyCaption{\powerSeriesUniform}{\modelUniform}
}{figPowerAccuracyUniformUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_old_power_accuracy_omega_median.pdf}{
    \powerAccuracyCaption{\powerSeriesUniform}{\modelOld}
}{figPowerAccuracyUniformOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_u-shaped_power_accuracy_omega_median.pdf}{
    \powerAccuracyCaption{\powerSeriesUniform}{\modelUshaped}
}{figPowerAccuracyUniformUshaped}


\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_dpp_power_accuracy_omega_median.pdf}{
    \powerAccuracyCaption{\powerSeriesOld}{\modelDPP}
}{figPowerAccuracyOldDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_uniform_power_accuracy_omega_median.pdf}{
    \powerAccuracyCaption{\powerSeriesOld}{\modelUniform}
}{figPowerAccuracyOldUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_old_power_accuracy_omega_median.pdf}{
    \powerAccuracyCaption{\powerSeriesOld}{\modelOld}
}{figPowerAccuracyOldOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_u-shaped_power_accuracy_omega_median.pdf}{
    \powerAccuracyCaption{\powerSeriesOld}{\modelUshaped}
}{figPowerAccuracyOldUshaped}



%% Power psi results
\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_dpp_power_psi_mode.pdf}{
    \powerPsiCaption{\powerSeriesExp}{\modelDPP}
}{figPowerPsiExpDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_uniform_power_psi_mode.pdf}{
    \powerPsiCaption{\powerSeriesExp}{\modelUniform}
}{figPowerPsiExpUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_old_power_psi_mode.pdf}{
    \powerPsiCaption{\powerSeriesExp}{\modelOld}
}{figPowerPsiExpOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_u-shaped_power_psi_mode.pdf}{
    \powerPsiCaption{\powerSeriesExp}{\modelUshaped}
}{figPowerPsiExpUshaped}


\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_dpp_power_psi_mode.pdf}{
    \powerPsiCaption{\powerSeriesUniform}{\modelDPP}
}{figPowerPsiUniformDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_uniform_power_psi_mode.pdf}{
    \powerPsiCaption{\powerSeriesUniform}{\modelUniform}
}{figPowerPsiUniformUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_old_power_psi_mode.pdf}{
    \powerPsiCaption{\powerSeriesUniform}{\modelOld}
}{figPowerPsiUniformOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_u-shaped_power_psi_mode.pdf}{
    \powerPsiCaption{\powerSeriesUniform}{\modelUshaped}
}{figPowerPsiUniformUshaped}


\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_dpp_power_psi_mode.pdf}{
    \powerPsiCaption{\powerSeriesOld}{\modelDPP}
}{figPowerPsiOldDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_uniform_power_psi_mode.pdf}{
    \powerPsiCaption{\powerSeriesOld}{\modelUniform}
}{figPowerPsiOldUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_old_power_psi_mode.pdf}{
    \powerPsiCaption{\powerSeriesOld}{\modelOld}
}{figPowerPsiOldOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_u-shaped_power_psi_mode.pdf}{
    \powerPsiCaption{\powerSeriesOld}{\modelUshaped}
}{figPowerPsiOldUshaped}



%% Power dispersion results
\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_dpp_power_omega_median.pdf}{
    \powerDispersionCaption{\powerSeriesExp}{\modelDPP}
}{figPowerDispersionExpDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_uniform_power_omega_median.pdf}{
    \powerDispersionCaption{\powerSeriesExp}{\modelUniform}
}{figPowerDispersionExpUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_old_power_omega_median.pdf}{
    \powerDispersionCaption{\powerSeriesExp}{\modelOld}
}{figPowerDispersionExpOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_u-shaped_power_omega_median.pdf}{
    \powerDispersionCaption{\powerSeriesExp}{\modelUshaped}
}{figPowerDispersionExpUshaped}


\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_dpp_power_omega_median.pdf}{
    \powerDispersionCaption{\powerSeriesUniform}{\modelDPP}
}{figPowerDispersionUniformDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_uniform_power_omega_median.pdf}{
    \powerDispersionCaption{\powerSeriesUniform}{\modelUniform}
}{figPowerDispersionUniformUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_old_power_omega_median.pdf}{
    \powerDispersionCaption{\powerSeriesUniform}{\modelOld}
}{figPowerDispersionUniformOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_u-shaped_power_omega_median.pdf}{
    \powerDispersionCaption{\powerSeriesUniform}{\modelUshaped}
}{figPowerDispersionUniformUshaped}


\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_dpp_power_omega_median.pdf}{
    \powerDispersionCaption{\powerSeriesOld}{\modelDPP}
}{figPowerDispersionOldDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_uniform_power_omega_median.pdf}{
    \powerDispersionCaption{\powerSeriesOld}{\modelUniform}
}{figPowerDispersionOldUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_old_power_omega_median.pdf}{
    \powerDispersionCaption{\powerSeriesOld}{\modelOld}
}{figPowerDispersionOldOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_u-shaped_power_omega_median.pdf}{
    \powerDispersionCaption{\powerSeriesOld}{\modelUshaped}
}{figPowerDispersionOldUshaped}



%% Power psi probability results
\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_dpp_power_psi_prob.pdf}{
    \powerPsiProbCaption{\powerSeriesExp}{\modelDPP}
}{figPowerPsiProbExpDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_uniform_power_psi_prob.pdf}{
    \powerPsiProbCaption{\powerSeriesExp}{\modelUniform}
}{figPowerPsiProbExpUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_old_power_psi_prob.pdf}{
    \powerPsiProbCaption{\powerSeriesExp}{\modelOld}
}{figPowerPsiProbExpOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_u-shaped_power_psi_prob.pdf}{
    \powerPsiProbCaption{\powerSeriesExp}{\modelUshaped}
}{figPowerPsiProbExpUshaped}


\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_dpp_power_psi_prob.pdf}{
    \powerPsiProbCaption{\powerSeriesUniform}{\modelDPP}
}{figPowerPsiProbUniformDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_uniform_power_psi_prob.pdf}{
    \powerPsiProbCaption{\powerSeriesUniform}{\modelUniform}
}{figPowerPsiProbUniformUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_old_power_psi_prob.pdf}{
    \powerPsiProbCaption{\powerSeriesUniform}{\modelOld}
}{figPowerPsiProbUniformOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_u-shaped_power_psi_prob.pdf}{
    \powerPsiProbCaption{\powerSeriesUniform}{\modelUshaped}
}{figPowerPsiProbUniformUshaped}


\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_dpp_power_psi_prob.pdf}{
    \powerPsiProbCaption{\powerSeriesOld}{\modelDPP}
}{figPowerPsiProbOldDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_uniform_power_psi_prob.pdf}{
    \powerPsiProbCaption{\powerSeriesOld}{\modelUniform}
}{figPowerPsiProbOldUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_old_power_psi_prob.pdf}{
    \powerPsiProbCaption{\powerSeriesOld}{\modelOld}
}{figPowerPsiProbOldOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_u-shaped_power_psi_prob.pdf}{
    \powerPsiProbCaption{\powerSeriesOld}{\modelUshaped}
}{figPowerPsiProbOldUshaped}



%% Power dispersion prob results
\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_dpp_power_omega_prob.pdf}{
    \powerDispersionProbCaption{\powerSeriesExp}{\modelDPP}
}{figPowerDispersionProbExpDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_uniform_power_omega_prob.pdf}{
    \powerDispersionProbCaption{\powerSeriesExp}{\modelUniform}
}{figPowerDispersionProbExpUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_old_power_omega_prob.pdf}{
    \powerDispersionProbCaption{\powerSeriesExp}{\modelOld}
}{figPowerDispersionProbExpOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/exp_u-shaped_power_omega_prob.pdf}{
    \powerDispersionProbCaption{\powerSeriesExp}{\modelUshaped}
}{figPowerDispersionProbExpUshaped}


\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_dpp_power_omega_prob.pdf}{
    \powerDispersionProbCaption{\powerSeriesUniform}{\modelDPP}
}{figPowerDispersionProbUniformDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_uniform_power_omega_prob.pdf}{
    \powerDispersionProbCaption{\powerSeriesUniform}{\modelUniform}
}{figPowerDispersionProbUniformUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_old_power_omega_prob.pdf}{
    \powerDispersionProbCaption{\powerSeriesUniform}{\modelOld}
}{figPowerDispersionProbUniformOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/uniform_u-shaped_power_omega_prob.pdf}{
    \powerDispersionProbCaption{\powerSeriesUniform}{\modelUshaped}
}{figPowerDispersionProbUniformUshaped}


\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_dpp_power_omega_prob.pdf}{
    \powerDispersionProbCaption{\powerSeriesOld}{\modelDPP}
}{figPowerDispersionProbOldDPP}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_uniform_power_omega_prob.pdf}{
    \powerDispersionProbCaption{\powerSeriesOld}{\modelUniform}
}{figPowerDispersionProbOldUniform}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_old_power_omega_prob.pdf}{
    \powerDispersionProbCaption{\powerSeriesOld}{\modelOld}
}{figPowerDispersionProbOldOld}

\mFigure{../../power-comparison/results/pymsbayes-results/plots/old_u-shaped_power_omega_prob.pdf}{
    \powerDispersionProbCaption{\powerSeriesOld}{\modelUshaped}
}{figPowerDispersionProbOldUshaped}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SUPPORTING INFO %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{page}{1}

\singlespacing

\renewcommand{\refname}{\noindent\MakeUppercase{\LARGE\sffamily\upshape Supporting Information}}

% PUT MAIN TEXT CITATION HERE
% \begin{thebibliography}{1}
% \providecommand{\natexlab}[1]{#1}
% \providecommand{\url}[1]{\texttt{#1}}
% \providecommand{\urlprefix}{URL }

% \bibitem

% \end{thebibliography}


%% SUPPL TABLES %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\setcounter{table}{0}


\end{document}

